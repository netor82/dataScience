---
title: "Proyecto Final"
author: "Manuel Calderón y Ernesto Rivera"
date: '2022-07-28'
output: html_document
editor_options: 
  markdown: 
    wrap: sentence
---
```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(kableExtra) # render de tablas
```

# Entendimiento del negocio

## Determinar los objetivos de negocio

### Objetivos de negocio

1.  Investigar e identificar los consumos de carne en el transcurso de los años, de regiones específicas, para aplicar un análisis de viabilidad en la producción de ciertos grupos cárnicos, de acuerdo a la región de análisis.

2.  Obtener un criterio sobre estos consumos contra producción, para así presupuestar una inversión futura en la producción de productos con los consumos más elevados o con tendencia a un crecimiento.

3.  Prever la demanda de productos cárnicos específicos en la región para los futuros años.

4.  Analizar la posibilidad de disminución o eliminación de la producción, inversión o presupuestación de algún producto cárnico poco consumido o con tendencias a disminuir.

5.  Determinar si el rumbo de producción se verá afectado por consumos futuros en las regiones de distribución de los distintos grupos cárnicos analizados.

### Criterios de éxito

1.  Se realiza un incremento de la inversión en la producción de los productos cárnicos específicos de acuerdo a las demandas de consumo, donde se tiene una producción no suficiente.

2.  Se logra un incremento de ventas de los productos producidos en un 10% anual.

3.  Disminución de los desperdicios de carnes al llevar a cabo una producción más acertada en al menos un 5%, se busca una meta de desperdicios de solo un 2%.

4.  Aumento de las ganancias al mantener la producción de los productos más consumidos y evitar la pérdida de los productos menos consumidos, se esperan obtener márgenes de al menos un 30%.

5.  Disminución de costes en desecho de productos no consumidos por desperdicios al almacenar, ya sea por una demanda baja o porque no logró salir del inventario, o sobre exceso de producción de productos que noten una variación amplia de consumo contra producción.

## Evaluación de la situación actual

### Inventario de recursos

Por parte de la empresa, ésta cuenta con los archivos digitales de estudios de consumo y producción de diferentes países del mundo obtenidos de internet.

Las fuentes de almacenamiento serán a nivel de la nube y manejados en distintos sitios web, como google drive para el almacenamiento de documentos, tableau public para el manejo visual de los análisis (dado que por ahora no se contarán con licencias), github para respaldos y almacenamiento de códigos.
Se aplicará como software de programación R, por que se usarán los programas Rstudio y Jupyter Notebooks.

A nivel físico y de personal, se contarán con 2 computadoras, junto con 2 personas del área de TI y Análisis.

### Requerimientos

Actualmente la empresa cuenta con una serie de problemas en el análisis de datos, ya que no tiene una forma de visualización clara o eficiente, lo que impide llevar a cabo una serie de objetivos de planeación.

Por lo anterior, se requiere una serie de visualizaciones que permitan el análisis de los valores de consumo y producción por año de los grupos cárnicos utilizados en los países de las sucursales del negocio y su tendencia en el ámbito internacional.
Esto, de ser posible, por medio de un dashboard que reúna los gráficos pertinentes.

Además, se requiere una predicción de consumo/producción futuro, para así lograr cumplir las previsiones de presupuestos y estimaciones de la empresa.
Esto con el fin de realizar mejores inversiones en los productos con mayor demanda.

### Supuestos

1.  Los archivos de los análisis de los datos mostrarán información verídica, confiable y completa.

2.  Las licencias, a pesar de ser libres, bastarán para cumplir los objetivos de la minería de datos.

3.  Los desarrolladores y analistas tendrán el suficiente conocimiento y entendimiento del proyecto para llevar a cabo los objetivos.

4.  El resultado final será suficiente para llevar a cabo los análisis y predicciones requeridas.

### Restricciones

1.  Se cuenta solo con 2 personas del área de desarrollo de software para elaboración del proyecto, por lo tanto, se limita el conocimiento del área cárnica.

2.  Se cuenta con 2 laptops para la elaboración del proyecto del proyecto, una por desarrollador.

3.  Por un tema de reducción de costos, se utilizará Tableau Public a sabiendas que existen limitantes en las funcionalidades.

4.  Se cuenta con una fecha de entrega determinada sin posibilidades de retrasos.

5.  Se cuentan con datos reales hasta el 2020.

### Riesgos y contingencias

1.  Existe el riesgo de no cumplir con el plazo de tiempo.
    En caso de cercanías de la entrega se deberán hacer extras para la finalización del mismo.

2.  Problemas técnicos o de perdida de equipo.
    Como contingencia se deberá mantener un respaldo constante utilizando github o Google drive.

3.  Problemas con los datos suministrados.
    Dado que se podrían ver serios retrasos, se debe aplicar una selección y limpieza lo antes posible.
    De no ocurrir, podría materializarse el riesgo descrito en el primer punto sobre no cumplir el plazo.

### Beneficios

A un nivel costo beneficio, se espera que el proyecto brinde estimaciones de consumos de productos cárnicos específicos, de manera que se pueda definir una producción óptima, evitando así problemas de sobreproducción o, caso contrario, se produzca menos comparado con la demanda del mercado.

A nivel de planeación, se espera disminuir el tiempo de análisis al tener una mejor visualización de las tendencias de consumo y producción.
Ello permitiría un mejor uso presupuestario con respecto a la inversión en productos de mayor consumo, por ende aumentar las ventas y evitar pérdidas por sobreproducción.

## Plan del proyecto

### Recursos

![](times.png)

### Evaluación inicial de herramientas y técnicas

Dado que como los consumos son precedidos por un tema de linealidad de tiempo, donde tanto el consumo como la producción tienden a tomar un incremento en el transcurso del tiempo, el tiempo se convierte en un atributo donde el orden importa.

Por lo que se decidió aplicar una serie de tiempo con un red neuronal recurrente (RNN).
Para el caso de las métricas se utilizarán el RMSE (error cuadrático medio), el MAPE (Mean Absolute Percent Error), y el r-squared score.
Esto se aplicará en R para la creación de los modelos.

## Determinar los objetivos de minería de datos

### Objetivos de minería de datos

El objetivo de la minería de datos es predecir el consumo y la producción anuales de los países de interés en cuatro tipos de productos cárnicos para los próximos 2 años de datos.

### Criterios de éxito (desde la perspectiva de minería de datos)

Como éxito se espera que la predicción antes mencionada tenga un nivel de confianza de al menos 80%.

----

# Fase de entendimiento de los datos

## Recopilación inicial de datos

### Lista de fuentes de datos requeridos

1.  OECD, Consumo de carne.
    Conjunto de datos sobre el consumo de carne mundial, datos recopilados y filtrados por la Organización para la Cooperación Económica y Desarrollo - [OECD](https://data.oecd.org/) por sus siglas en inglés.
    Los datos son un subconjunto de los datos emitidos por el reporte [OECD-FAO Agricultural Outlook (Edition 2021)](https://www.oecd-ilibrary.org/agriculture-and-food/data/oecd-agriculture-statistics/oecd-fao-agricultural-outlook-edition-2021_4bde2d83-en), que incluye datos desde 1970 con proyecciones para los años 2021-2029, y que cubre estadísticas sobre mercados como cereales, aceite de semillas, productos lácteos, algodón y otros.

2.  ISO, Códigos de los países.
    Utilizados para hacer uniones entre diferentes conjuntos de datos.

3.  FAO, Cultivos y productos ganaderos.
    Este reporte emitido por la Organización de Comida y Agricultura de la ONU (FAO por sus siglas en inglés) contiene la cantidad de carne producida por cada país.
    Actualizado por última vez en Febrero de 2022.


### Método de acceso

1.  Consumo de carne.
    Los datos recopilados por la OECD se encuentran públicamente accesibles desde su sitio web, en particular el [reporte sobre consumo de carne](https://data.oecd.org/agroutput/meat-consumption.htm).

2.  ISO Country Codes - Global.
    Acceso público en el sitio de [kaggle](https://www.kaggle.com/datasets/andradaolteanu/iso-country-codes-global).

3.  Cultivos y productos ganaderos.
    Datos exportados desde la página de [estadísticas de la FAO](https://www.fao.org/faostat/en/#data/QCL), en formato CSV sin separador de miles, utilizando los siguientes filtros:

    a.  Países: "todos"

    b.  Ítemes:

        i.  Meat, cattle

        ii. Meat, chicken

        iii. Meat, pig

        iv. Meat, sheep

    c.  Elementos: "Production Quantity".

    d.  Años: "todos".

### Descripción de los datos
<a href="#" id="descripcion.datos"></a>
Las variables a utilizar:

1.  Año: en el dataset de la FAO se llama "Year", en el de la OECD se llama "Time".
    Representa el año de la medición.

2.  Valor: en el dataset de la FAO la columna "Value" corresponde al total de producción en toneladas, en el dataset de la OECD la columna con el mismo nombre representa el total del consumo en miles de toneladas.

3.  Unidad de medida: en el dataset de la FAO las unidades de valor son las toneladas, en el de la OECD pueden ser "miles de toneladas" o "kg per cápita".

4.  País: en el dataset de la FAO se llama "Area" y corresponde al nombre del país de la medición por su nombre en inglés, mientras que en el de la OECD se llama "Location" y corresponde al código ISO de 3 caracteres del país.

5.  Tipo de carne:

    a.  En el dataset de la FAO la columna se llama "Item" y puede tomar cualquiera de los valores:

        i.  Meat, beef

        ii. Meat, cattle

        iii. Meat, pig

        iv. Meat, sheep

    b.  Por otro lado, en el de la OECD la columna se llama "Subject" y toma los valores de:

        i.  Beef

        ii. Pig

        iii. Poultry

        iv. Sheep.

El cruce de la información se realiza utilizando la siguiente tabla:

![](fao_oecd.png)

Como lo menciona la tabla, para unir "Area" y "Location" se necesita de un tercer dataset intermedio para convertir los códigos en "Location" a nombres de países como en "Area".

Sobre los datasets

1.  OECD: 12160 registros sobre consumo de 35 países.

2.  OFA: 42358 registros sobre producción de 209.

3.  Países: 246 registros con nombre de los países junto con sus códigos en 2 letras, 3 letras, numérico e ISO 3166.

### Exploración de los datos

Una vez unidos los datasets, se puede observar que los valores de ambos datasets corresponden a medidas reales con comportamiento similar.

Gráficos generados usando [python y Jypiter notebook](https://github.com/netor82/dataScience/blob/master/miner%C3%ADa/proyecto/entregable1/Revisar%20datos%20de%20proyecto.ipynb).
![](totalPorTipo.png)



Valores sumados por año:

![](total.png)

Existe una correlación de 99% entre las cantidades de consumo y producción.

Matriz de correlación para valores numéricos:

![](correlac.png)

### Calidad de datos

El **dataset OECD** sobre consumo, trae información sobre el consumo de carnes de 35 países, para un total de 12160 registros.
De los cuales, 247 valores son iguales a 0, pero no los descartamos pues puede ser que un país no haya tenido producción de ese tipo de carne en un año en particular, o dada su ubicación geográfica o su tipo de actividad económica.

Es este mismo dataset de OECD sobre consumo, una columna viene con todos sus valores en nulo (evidencia también en la sección siguiente), dicha columna se descartarà al limpiar los datos.

Con respecto a los códigos de país, no requiere trabajo adicional pues todos los códigos corresponden a países según los códigos ISO.

Los valores están en miles de toneladas, deben ser entonces multiplicados por 1000 para que tengan la misma escala que en el otro dataset.

El dataset de la FAO sobre datos de producción, contiene un total de 42358 registros, con información de 209 países.

Además, el dataset de FAO tiene 68 valores nulos que serán omitidos (evidencia en la siguiente sección).

Con respecto al nombre de los países, sí se requiere manipulación de los datos para que exista una correspondencia con el dataset de los países.
En total existen 39 inconsistencias.
Sin embargo, sólo es necesario modificar 7 de ellos por no estar todos los países representados en el dataset de OECD.

Los países a modificar sus nombres en este dataset de la FAO son:

![](country.png)

----

# Fase de Preparación de los datos

Dado que los archivos de datos provienen de fuentes diferentes, se hizo necesario aplicar un proceso de limpieza para poder cruzar la información.
Para ello, se necesitó una tercera fuente de datos -países- y cambiar los valores citados en la tabla anterior.


![](dfJoin.png)

## Selección de los datos

```{r, echo=FALSE}
head2 <- function(df, n){
  return(kable(head(df, n)) %>% kable_styling(full_width = F))
}
```


```{r}
dfFao <- read.csv('./../entregable1/FAOSTAT.csv', header = TRUE, sep=",", stringsAsFactors = FALSE)
head2(dfFao, 2)
```

Cantidad de elementos en dfFao
```{r}
nrow(dfFao)
```

Cantidad de elementos con NA en el dataset
```{r}
colSums(is.na(dfFao))
```


Cantidad de países en el Dataset de dfFao
```{r}
length(unique(dfFao$Area))
```


```{r}
dfCountries <- read.csv('./../entregable1/iso-country-codes.csv', header = TRUE, sep=",", stringsAsFactors = FALSE)
head2(dfCountries, 2)
```

Cantidad de elementos con NA en el dataset
```{r}
colSums(is.na(dfCountries))
```

```{r}
dfConsumption <- read.csv('./../entregable1/oecd_meat_consumption.csv', header = TRUE, sep=",", stringsAsFactors = FALSE)
head2(dfConsumption, 2)
```

```{r}
nrow(dfConsumption)
```
Cantidad de países en el Dataset de dfFao es 38 = 35 países + 3 valores especiales de valores calculados en el dataset, a saber "BRICS" (Brasil, Russia, India, China y Sur África), "WLD" (World) y "OECD" (países de la OECD).
```{r}
length(unique(dfConsumption$LOCATION))
unique(dfConsumption$LOCATION)
```


Cantidad de elementos con NA en el dataset
```{r}
colSums(is.na(dfConsumption))
```


## Limpieza de los datos

Nota, el siguiente código de R sigue el mismo algoritmo aplicado en el documento de [python](https://github.com/netor82/dataScience/blob/timeSeries/miner%C3%ADa/proyecto/entregable1/Revisar%20datos%20de%20proyecto.ipynb).


### Pasos para limpiar dfCountries

1.  Seleccionar solo aquellas columnas necesarias.
2.  Renombrar las columnas con el mismo nombres de las columnas en los otros dataset para luego hacer los joins.
3.  Revisar qué valores de dfCountries no hacen correspondencia con los códigos o nombres usados en los otros dos datasets.

**Paso 1 y 2**

```{r}
dfCountries = dfCountries[, c('Alpha.3.code', 'English.short.name.lower.case')]
colnames(dfCountries) <- c('LOCATION', 'Area')
head2(dfCountries, 2)
```

**Paso 3: emparejado de valores**

Función utilitaria para unir dos dataframes, usando left join

```{r, echo=FALSE}
unirDf <- function(df1, df2, columna){
    df1 = merge(df1, df2, by=columna, all.x=TRUE) # left join
    return(df1)
}
```

Valores que están en _dfConsumption_ pero no en _dfCountries_.

```{r}
dfUnicosEnConsumo <- data.frame(unique(dfConsumption[,'LOCATION']))
colnames(dfUnicosEnConsumo)  <- c("LOCATION")

dfJoinedConsumptionAndCountries <- unirDf(dfUnicosEnConsumo, dfCountries, 'LOCATION')
dfJoinedConsumptionAndCountries[is.na(dfJoinedConsumptionAndCountries$Area),]
```

Esto es esperado, pues el dataset de consumo de OEDC _dfConsumption_ usa estos tres valores anteriores como "especiales" para su propio análisis, por ejemplo WLD o *World* es el valor calculado que suma a todo el mundo.

Ahora, quitamos esos valores, y nos dejamos de Consumption los valores de los cuales sí tenemos el país correspondiente según la columna *Location*.

```{r}
dfConsumptionCountries <- na.omit(dfJoinedConsumptionAndCountries)
head2(dfConsumptionCountries, 5)
```

Buscamos valores de países en FAO que no tengan valores en Consumption.

```{r}
corroborarValoresEnFAO <- function(df){
  valoresUnicos = unique(dfFao[,'Area'])  
  dfUnicosEnFao = data.frame(valoresUnicos, valoresUnicos)
  colnames(dfUnicosEnFao) = c('Area', 'Dummy')
  result = unirDf(df, dfUnicosEnFao, 'Area')
    
  #seleccionar los datos que de resultado a la derecha no tenga nada
  result = result[is.na(result$Dummy),]
  return(result)
}

corroborarValoresEnFAO(dfConsumptionCountries)
```


Se hace correción a esos 7 valores para poder unir ambos datasets.

```{r}
corregirValorEnFao <- function(antes, desp, columna='Area'){
  # guardar valor en el GlobalEnv para que se salve fuera de la función
  .GlobalEnv$dfFao[ dfFao[, columna] == antes, columna]  <- desp
}

corregirValorEnFao('Republic of Korea', 'South Korea')
corregirValorEnFao('United States of America', 'United States')
corregirValorEnFao('Iran (Islamic Republic of)', 'Iran')
corregirValorEnFao('Russian Federation', 'Russia')
corregirValorEnFao('Viet Nam', 'Vietnam')
corregirValorEnFao('United Kingdom of Great Britain and Northern Ireland', 'United Kingdom')
corregirValorEnFao('Türkiye', 'Turkey')

corroborarValoresEnFAO(dfConsumptionCountries)

```

```{r}
head2(dfCountries, 5)
```

### Pasos para limpiar dfConsumption

1. Unir los datos de Consumo con los países.
2. Quitar los códigos de 'Location' propios del análisis de la OECD.
3. Quitar columnas innecesarias.

**Paso 1. Unir datos con dataframe de países**

```{r}
dfConsumption = merge(dfConsumption, dfCountries, by='LOCATION', all.x=TRUE) # left join
head2(dfConsumption, 5)
```

```{r}
unique(dfConsumption[ is.na(dfConsumption$Area), 'LOCATION'])
```

**Paso 2. Remover Location extras**

Remover filas cuando el 'Location' es 'WLD', 'OECD' o 'BRICS'.

Esos son valores totales usados por OECD para comparaciones que no son necesarios para nuestro análisis.

```{r}

dfConsumption = dfConsumption[-which(is.na(dfConsumption$Area)), ]

head2(dfConsumption, 5)
```

Valores de *Area* que no podrían cruzarse:

```{r}
unique(dfConsumption[ is.na(dfConsumption$Area), 'LOCATION'])
```

**Paso 3. Remover columnas innecesarias**

Descubriendo cuáles columnas son innecesarias:

-   Location (se sustituye por Area).
-   Flag Codes que son todos valores nulos.
-   Frecuencia: que siempre es A de Anual.
-   Indicador: que siempre es MEATCONSUMP.
-   Columnas de códigos redundantes como Year Code, Item Code, Element Code, Area Code

Todos sus valores son nulos:

```{r}
unique(dfConsumption[, 'Flag.Codes'])
```

Todos sus valores son iguales:

```{r}
unique(dfConsumption[, 'FREQUENCY'])
```

Todos sus valores son iguales:

```{r}
unique(dfConsumption[, 'INDICATOR'])
```

```{r}
dfConsumption = dfConsumption[c('Area', 'SUBJECT', 'MEASURE', 'TIME', 'Value')]
head2(dfConsumption, 5)
```

### Pasos para limpiar dfFao

Este dataset contiene datos de la producción total en toneladas.

1. Para nuestro análisis solo nos interesa la producción, para poder compararla con el consumo *dfConsumption*.
2. Cambia los valores de los tipos de carnes para coincidir con los valores en *dfConsumption*.
3. Remover columnas valores faltantes.

**Paso 1. Seleccionar columnas a usar**

Antes:

```{r}
head2(dfFao, 3)
```

Después:

```{r}
dfFao = dfFao[c('Area', 'Item', 'Year', 'Value')]
head2(dfFao, 3)
```

**Paso 2. Cambiar valores de tipos de carnes**

Antes:

```{r}
unique(dfFao['Item'])
```

Después:

```{r}
corregirValorEnFao('Meat, cattle', 'BEEF', 'Item')
corregirValorEnFao('Meat, chicken', 'POULTRY', 'Item')
corregirValorEnFao('Meat, sheep', 'SHEEP', 'Item')
corregirValorEnFao('Meat, pig', 'PIG', 'Item')

unique(dfFao['Item'])
```

**Paso 3. Remover columnas valores faltantes**

Valores faltantes por columna de los `r nrow(dfFao)` registros:

```{r}
colSums(is.na(dfFao))
```


```{r}
dfFao = dfFao[ - which(is.na(dfFao$Value)), ]
head2(dfFao, 5)
```


Cantidad final de registros en dfFao es `r nrow(dfFao)`.
```{r, echo=FALSE}
nrow(dfFao)
```
Valores faltantes:
```{r}
colSums(is.na(dfFao))
```


## Construcción de nuevos datos (atributos)

No se hace necesario contruir datos nuevos.

## Transformaciones aplicadas a los datos

A este punto, los datos están listos para ser unidos, utlizado los valores descritos en la sección de [descripción de los datos](#descripcion.datos)

---

# Fase de modelado

## Selección de las técnicas a utilizar

Se utilizaron dos técnicas para crear los modelos:

1. Árbol de decisión para regresión
2. Red Neuronal

Para estimar su eficacia se utilizó el MSE (median squared error).

## Construcción del modelo

El problema se plantea como **una serie de tiempo**, por lo que se acomoda usando
el valor en el tiempo _T_ y el valor en el tiempo _T+1_ en la misma fila.


### Selección de los parámetros (justificar su selección)

**1. Árbol de decisión**

No se utilizó ningún hiperparámetro para este modelo.  Código en python:

```{python eval=FALSE}
clf = DecisionTreeRegressor()
clf.fit(X_train,Y_train)
Y_pred_train = clf.predict(X_train)
```

La evaluación se hizo posteriormente usando MSE.

**2. Red Neuronal**

La red neuronal se contruyó de tres capas:
    
a. Capa de entrada con 41 nodos.  Luego del _hot enconding_ quedan 35 columnas de países, 4 de tipo de carne, una del año, y la del consumo en el tiempo T.
b. Capa intermedia de 32 nodos
c. Capa de salida con un nodo pues la salida es una predicción.

Usa el MSE como estimador de pérdida, y se utilizan 300 epochs.

### Ejecución

La ejecución se divide en dos partes: una para Consumo y la segunda para Producción.

Durante la ejecución se recolectan los valores predichos para el año 2020 junto con los estimadores de error, dichos valores se muestran en la sección siguiente.

```{python eval=FALSE}
ejecutarModelos(dfTrainConsumo, dfTestConsumo, dfPredConsumo, 'Consumption_x', 'Consumption_y', 'Consumo')
ejecutarModelos(dfTrainProd, dfTestProd, dfPredProd, 'Production_x', 'Production_y', 'Producción')
```

Código disponible [aquí](https://github.com/netor82/dataScience/blob/timeSeries/miner%C3%ADa/proyecto/entregable1/Revisar%20datos%20de%20proyecto.ipynb).


### Descripción de los modelos obtenidos

Entre los modelos obtenidos después de la ejecución ambos cumplen con el propósito de la predicción a un año (T + 1), siendo cercanamente acertadas ambas, aunque para efectos de MSE se logran mejores resultados en el Árbol de decisión, a nivel de entrenamiento y testeo se logran valores muy diferenciados en las evaluaciones del RNN, por lo cual generan dudas sobre si realmente cumplirá las metas de predicción en todos los posibles casos para fines prácticos si se desea aplicar este modelo se tendría que hacer mejoras. (más detalles en la sección de resultados)

## Evaluación de los modelos

### Resultados

**Valores de MSE** de ambos modelos para una corrida

- Test = con datos de pruebas
- Train = con datos de entrenamiento

```{r echo=FALSE}
mse = data.frame(Tipo = c('Árbol de Decisión Train', 'Árbol de Decisión Test', 'Red Neural Train', 'Red Neural Test'),
                 Consumo = c(0, 284268, 7.8* 10**10, 8.62*10**10),
                 Producción = c(0, 241618, 3.5486*10**11, 2.2067*10**11))
head2(mse, 4)
```

Como observación, los valores de SME para la Red Neuronal están en hasta 6 órdenes de magnitud mayor, es decir, más alejados de los valores reales.

Tras la selección del módelo también se aplicó un R2 obteniendo resultados de 1.0 por lo cual se cumple más de 80%, aunque se podría tomar como un overfitting del modelo a nivel del entreanmuiento pero se logra un 0.97 a nivel de test lo cual son grandes resultados igualmente.

![](tree_res.png)


### Seleccionar el mejor modelo

El mejor resultado lo arroja el modelo que usa el **Árbol de Decisión**, tanto para Consumo como para Producción.

En esta tabla se muestran las sumas del **total de los valores** predichos por los algoritmos junto con los datos reales para 2020.

En ambos casos, los resultados por el Árbol de Decisión se acercan más a los datos reales que sus análogos producidos por la Red Neuronal.

```{r echo=FALSE}
comparacionDatos = data.frame(
  Tipo = c('Árbol de decisión', 'Red Neuronal', 'Dato real'),
  Consumo = c(253566480, 253703968, 246539331),
  Producción = c(249278633, 209699168, 238388169)
)
head2(comparacionDatos, 4)
```


----

# Diseño y construcción del dashboard

[Dashboard de Tableau](https://public.tableau.com/views/Proyecto_16587985093510/Dashboard1?:language=en-US&:display_count=n&:origin=viz_share_link)

El filtro por **Año** está de 1990 a 2020 por defecto, que corresponde a los datos reales.

Sin embargo, también se puede **ampliar el rango** para incluir los **valores predichos** para el 2021 por el modelo seleccionado.

